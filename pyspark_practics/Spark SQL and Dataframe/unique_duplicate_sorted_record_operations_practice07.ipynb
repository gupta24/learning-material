{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4be1445-9fe0-4062-8d07-a6d4a732715b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=442497685451589#setting/sparkui/0918-051952-1zzv1vus/driver-7296092083699510497\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=442497685451589#setting/sparkui/0918-051952-1zzv1vus/driver-7296092083699510497\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7568586-ddfb-42b3-825b-abd1e0b4d49d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "------------- Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff393921-dc04-4328-ae5c-f6a0dc0a2cfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 10|  Anil| 50000|     18|\n| 11| Vikas| 75000|     16|\n| 12| Nisha| 40000|     18|\n| 13| Nidhi| 60000|     17|\n| 14| Priya| 80000|     18|\n| 15| Mohit| 45000|     18|\n| 16|Rajesh| 90000|     10|\n| 17| Raman| 55000|     16|\n| 18|   Sam| 65000|     17|\n| 15| Mohit| 45000|     18|\n| 13| Nidhi| 60000|     17|\n| 14| Priya| 90000|     18|\n| 18|   Sam| 65000|     17|\n+---+------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "data=[(10 ,'Anil',50000, 18),\n",
    "    (11 ,'Vikas',75000,  16),\n",
    "    (12 ,'Nisha',40000,  18),\n",
    "    (13 ,'Nidhi',60000,  17),\n",
    "    (14 ,'Priya',80000,  18),   \n",
    "    (15 ,'Mohit',45000,  18),\n",
    "    (16 ,'Rajesh',90000, 10),\n",
    "    (17 ,'Raman',55000, 16),\n",
    "    (18 ,'Sam',65000,   17),\n",
    "    (15 ,'Mohit',45000,  18),\n",
    "    (13 ,'Nidhi',60000,  17),      \n",
    "    (14 ,'Priya',90000,  18),  \n",
    "    (18 ,'Sam',65000,   17)\n",
    "]\n",
    "schema = ['id', 'name', 'salary', 'mngr_id']\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f8fbb0-f161-4e17-ad3d-55092686bf5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---------------- Find Unique Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da365f87-dc0d-45fc-8981-767323bd5602",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 10|  Anil| 50000|     18|\n| 12| Nisha| 40000|     18|\n| 11| Vikas| 75000|     16|\n| 13| Nidhi| 60000|     17|\n| 15| Mohit| 45000|     18|\n| 14| Priya| 80000|     18|\n| 16|Rajesh| 90000|     10|\n| 17| Raman| 55000|     16|\n| 18|   Sam| 65000|     17|\n| 14| Priya| 90000|     18|\n+---+------+------+-------+\n\ncount with all column :  10\n+---+------+\n| id|  name|\n+---+------+\n| 10|  Anil|\n| 11| Vikas|\n| 12| Nisha|\n| 13| Nidhi|\n| 15| Mohit|\n| 14| Priya|\n| 17| Raman|\n| 16|Rajesh|\n| 18|   Sam|\n+---+------+\n\ncount with some columns :  9\n"
     ]
    }
   ],
   "source": [
    "# find distinct record on all column of data frame\n",
    "df.distinct().show()\n",
    "cnt = df.distinct().count()\n",
    "print(\"count with all column : \", cnt)\n",
    "\n",
    "# find unique record on some columns\n",
    "df.select('id', 'name').distinct().show()\n",
    "cnt = df.select('id', 'name').distinct().count()\n",
    "print(\"count with some columns : \", cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12d96379-1280-4426-b875-ad4a39b36d03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---------------- Drop The Duplicates Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "321c7286-4b4a-4a11-bc81-5f0a88180923",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 10|  Anil| 50000|     18|\n| 12| Nisha| 40000|     18|\n| 11| Vikas| 75000|     16|\n| 13| Nidhi| 60000|     17|\n| 15| Mohit| 45000|     18|\n| 14| Priya| 80000|     18|\n| 16|Rajesh| 90000|     10|\n| 17| Raman| 55000|     16|\n| 18|   Sam| 65000|     17|\n| 14| Priya| 90000|     18|\n+---+------+------+-------+\n\nOut[24]: 10"
     ]
    }
   ],
   "source": [
    "# drop the duplicate records from data frame\n",
    "df1 = df.drop_duplicates(['id', 'name', 'salary', 'mngr_id'])\n",
    "df1.show()\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19184e9d-5051-4949-b330-702c988131f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "------------------ Sort The Record In Asc/Desc Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca6a7ed-97ed-4b75-afc8-0e6e296e3d72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 12| Nisha| 40000|     18|\n| 15| Mohit| 45000|     18|\n| 10|  Anil| 50000|     18|\n| 17| Raman| 55000|     16|\n| 13| Nidhi| 60000|     17|\n| 18|   Sam| 65000|     17|\n| 11| Vikas| 75000|     16|\n| 14| Priya| 80000|     18|\n| 16|Rajesh| 90000|     10|\n| 14| Priya| 90000|     18|\n+---+------+------+-------+\n\n+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 16|Rajesh| 90000|     10|\n| 14| Priya| 90000|     18|\n| 14| Priya| 80000|     18|\n| 11| Vikas| 75000|     16|\n| 18|   Sam| 65000|     17|\n| 13| Nidhi| 60000|     17|\n| 17| Raman| 55000|     16|\n| 10|  Anil| 50000|     18|\n| 15| Mohit| 45000|     18|\n| 12| Nisha| 40000|     18|\n+---+------+------+-------+\n\n+---+------+------+-------+\n| id|  name|salary|mngr_id|\n+---+------+------+-------+\n| 14| Priya| 90000|     18|\n| 16|Rajesh| 90000|     10|\n| 14| Priya| 80000|     18|\n| 11| Vikas| 75000|     16|\n| 18|   Sam| 65000|     17|\n| 13| Nidhi| 60000|     17|\n| 17| Raman| 55000|     16|\n| 10|  Anil| 50000|     18|\n| 15| Mohit| 45000|     18|\n| 12| Nisha| 40000|     18|\n+---+------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# sort in ascending order\n",
    "df1.sort(\"salary\").show()\n",
    "\n",
    "# sort in descending order\n",
    "df1.sort(col(\"salary\").desc()).show()\n",
    "\n",
    "# sort with multiple column\n",
    "df1.sort(col(\"salary\").desc(), col(\"name\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5a31345-f617-468d-9518-e1457a9fb1cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "--- leetcode question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55962066-5949-4dc4-a1c3-08b98986da98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+\n| id|name|refer_id|\n+---+----+--------+\n|  1|Will|    null|\n|  2|Jane|    null|\n|  3|Alex|       2|\n|  4|Bill|    null|\n|  5|Zack|       1|\n|  6|Mark|       2|\n+---+----+--------+\n\n+---+----+--------+\n| id|name|refer_id|\n+---+----+--------+\n|  1|Will|    null|\n|  2|Jane|    null|\n|  4|Bill|    null|\n|  5|Zack|       1|\n+---+----+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# report the all customer who is not refered by 2..\n",
    "# create df..\n",
    "leet_code_data = [\n",
    "    (1, 'Will', None),\n",
    "    (2, 'Jane', None),\n",
    "    (3, 'Alex', 2),\n",
    "    (4, 'Bill', None),\n",
    "    (5, 'Zack', 1),\n",
    "    (6, 'Mark', 2)\n",
    "]\n",
    "df2 = spark.createDataFrame(leet_code_data, ['id', 'name', 'refer_id'])\n",
    "df2.show()\n",
    "\n",
    "# we can solve by using filter\n",
    "df2.filter((col(\"refer_id\").isNull()) | (col(\"refer_id\") != 2)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b47700-3c9d-40a4-bdd3-a9e082d95ab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e21e6aa9-b083-473a-af72-41bbc9b7b26e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "find_unique_duplicate_sorted_record_operations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
